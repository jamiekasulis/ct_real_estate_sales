{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CT Statewide House Sales Transactions\n",
    "This notebook is for producing a cleaned version of the data from https://data.ct.gov/Housing-and-Development/Real-Estate-Sales-2001-2016/5mzw-sjtu?category=Housing-and-Development , which lists CT statewide sales transactions on individual properties from 2001-2016. This cleans the data in year-by-year sections and outputs csvs for each year. It then recomes the data in these csvs into one cleaned csv with all the data.\n",
    "\n",
    "View the raw data here: https://raw.githubusercontent.com/jamiekasulis/ct_real_estate_sales/master/Real_Estate_Sales_2001-2016.csv\n",
    "\n",
    "View the meanings of NonUseCodes here: file:///C:/Users/jleekas/Downloads/OPM-RealEstate_Codes.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Needed Cleaning\n",
    "* Trim whitespace and replace double-spaces with single-spaces (done)\n",
    "* Replace address abbreviations like \"LN\" with their full form, \"LANE\" (done)\n",
    "* Fix NonUseCodes. Should be ints only. Use 0 or -1 for absence of a NonUseCode. (done)\n",
    "* Remove duplicate transactions. (done)\n",
    "* Catch mispellings of towns and street names using Python fuzzywuzzy (do later, when you are ready to look at individual properties.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ There are several data cleaning notebooks because to run the processes on all the years of data at once has been taking so, so long.\n",
    "\n",
    "This is where I test my cleaning process on just a small sample of 2000 listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_raw_df():\n",
    "    \"\"\"\n",
    "    Return the raw df, which is uncleaned, to test cleaning repeatedly.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(\"https://media.githubusercontent.com/media/jamiekasulis/ct_real_estate_sales/master/data/Real_Estate_Sales_2001-2016.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset: top 2000 listings. Use this to test cleaning functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_raw_df():\n",
    "    \"\"\"\n",
    "    Return a sample of 2000 listings from the raw data. Use for testing.\n",
    "    \"\"\"\n",
    "    return make_raw_df()[0:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "sample = sample_raw_df()\n",
    "print(len(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trim whitespace at the ends and middle of fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_whitespace(df, column):\n",
    "    \"\"\"\n",
    "    Removes all trailing and leading whitespace in a string. Will also turn double spaces into single spaes.\n",
    "    \"\"\"\n",
    "    new_df = df.copy()\n",
    "    \n",
    "    for index in new_df.index:\n",
    "        new_df.loc[index,column] = str(new_df.loc[index,column]).strip().replace('  ', ' ')\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample = trim_whitespace(sample, 'Town')\n",
    "new_sample = trim_whitespace(new_sample, 'Address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert abbreviated street names to their full names.\n",
    "Will have to do more thorough Address cleaning later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "street_conversions = {\n",
    "    ' LN':' LANE',\n",
    "    ' RD':' ROAD',\n",
    "    ' ST':' STREET',\n",
    "    ' DR':' DRIVE',\n",
    "    ' PL':' PLACE',\n",
    "    ' HL': ' HILL',\n",
    "    ' TER': ' TERRACE'\n",
    "}\n",
    "def convert_address_street_abbreviations(df, conversions):\n",
    "    \"\"\"\n",
    "    Will go through all the rows in a copy of df and change street abbreviations to their full names,\n",
    "    i.e. \"10 CHESTER BROOKS LN\" will become \"10 CHESTER BROOKS LANE\".\n",
    "    \"\"\"\n",
    "    new_df = df.copy()\n",
    "    \n",
    "    # Iterate through each row\n",
    "    for index in new_df.index:\n",
    "        current = str(new_df.loc[index, 'Address']) # get current address\n",
    "        #print(current)\n",
    "        \n",
    "        for key in street_conversions.keys():\n",
    "            if key in current:\n",
    "                # DR is a special case because 'DR' in 'DRIVE' already. Avoid changing to 'DRIVEIVE'\n",
    "                if key != ' DR' or (key == ' DR' and ' DRIVE' not in current):\n",
    "                    new_df.loc[index, 'Address'] = current.replace(key, street_conversions[key])\n",
    "                break\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = convert_address_street_abbreviations(new_sample, street_conversions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CSVs for each year of listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_rows(df):\n",
    "    \"\"\"\n",
    "    Removes duplicate rows.\n",
    "    Rows are duplicates if they have the same serial number, ListYear, and town.\n",
    "    In most cases, there are just two copies of a row with the difference being that the second one is slightly\n",
    "    rounded.\n",
    "    Arbitrarily choose the first row and throw out subsequent duplicate rows.\n",
    "    \"\"\"\n",
    "    new_df = df.copy()\n",
    "    return new_df.drop_duplicates(['SerialNumber', 'ListYear', 'Town']) #, 'DateRecorded', 'Address'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = remove_duplicate_rows_duplicate_rows(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'SerialNumber', 'ListYear', 'DateRecorded', 'Town', 'Address',\n",
       "       'AssessedValue', 'SaleAmount', 'SalesRatio', 'PropertyType',\n",
       "       'ResidentialType', 'NonUseCode', 'Remarks'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_duplicate_rows(clean_df, raw_df):\n",
    "    \"\"\"\n",
    "    clean_df is a df with duplicates removed. raw_df is a df that has yet to have its duplicates removed.\n",
    "    Returns a df of the rows that are in clean_df but not in raw_df.\n",
    "    Recall that remove_duplicate_rows works on the columns 'SerialNumber', 'ListYear', and 'Town'.\n",
    "    \"\"\"\n",
    "    new_df = raw_df.copy()\n",
    "    # Create a new column, 'duplication', which is the string concatenation of the 3 columns that remove_duplicates\n",
    "    # checks to identify duplies. This creates what SHOULD be a unique identifier (although we will return the rows)\n",
    "    # who have 'duplication's in common with other rows.\n",
    "    new_df['SerialNumber'] = new_df['SerialNumber'].astype(str)\n",
    "    new_df['ListYear'] = new_df['ListYear'].astype(str)\n",
    "    new_df['duplication'] = new_df['SerialNumber'] + new_df['ListYear'] + new_df['Town']\n",
    "    \n",
    "    duplicates = new_df[0:0] # Create an empty df of duplicates\n",
    "    \n",
    "    # Iterate through all rows, identifying rows that have the same 'duplication' column\n",
    "    for index in new_df.index:\n",
    "        current_dupe = new_df.loc[index, 'duplication']\n",
    "        dupe_in_common = new_df[new_df['duplication'] == current_dupe]\n",
    "        if len(dupe_in_common) > 1:\n",
    "            duplicates = pd.concat([duplicates, dupe_in_common])\n",
    "    return duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SerialNumber</th>\n",
       "      <th>ListYear</th>\n",
       "      <th>DateRecorded</th>\n",
       "      <th>Town</th>\n",
       "      <th>Address</th>\n",
       "      <th>AssessedValue</th>\n",
       "      <th>SaleAmount</th>\n",
       "      <th>SalesRatio</th>\n",
       "      <th>PropertyType</th>\n",
       "      <th>ResidentialType</th>\n",
       "      <th>NonUseCode</th>\n",
       "      <th>Remarks</th>\n",
       "      <th>duplication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>20030</td>\n",
       "      <td>2002</td>\n",
       "      <td>04/24/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>10 BAUSOLA RD</td>\n",
       "      <td>91800</td>\n",
       "      <td>189900.0</td>\n",
       "      <td>48.341232</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200302002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>20030</td>\n",
       "      <td>2002</td>\n",
       "      <td>04/24/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>10 BAUSOLA RD</td>\n",
       "      <td>91800</td>\n",
       "      <td>189900.0</td>\n",
       "      <td>48.340000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200302002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>20030</td>\n",
       "      <td>2002</td>\n",
       "      <td>04/24/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>10 BAUSOLA RD</td>\n",
       "      <td>91800</td>\n",
       "      <td>189900.0</td>\n",
       "      <td>48.341232</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200302002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>20030</td>\n",
       "      <td>2002</td>\n",
       "      <td>04/24/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>10 BAUSOLA RD</td>\n",
       "      <td>91800</td>\n",
       "      <td>189900.0</td>\n",
       "      <td>48.340000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200302002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>20026</td>\n",
       "      <td>2002</td>\n",
       "      <td>03/04/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>109 LAKESIDE DR</td>\n",
       "      <td>96700</td>\n",
       "      <td>146000.0</td>\n",
       "      <td>66.232877</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200262002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>20026</td>\n",
       "      <td>2002</td>\n",
       "      <td>03/04/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>109 LAKESIDE DR</td>\n",
       "      <td>96700</td>\n",
       "      <td>146000.0</td>\n",
       "      <td>66.230000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200262002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>20026</td>\n",
       "      <td>2002</td>\n",
       "      <td>03/04/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>109 LAKESIDE DR</td>\n",
       "      <td>96700</td>\n",
       "      <td>146000.0</td>\n",
       "      <td>66.232877</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200262002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>20026</td>\n",
       "      <td>2002</td>\n",
       "      <td>03/04/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>109 LAKESIDE DR</td>\n",
       "      <td>96700</td>\n",
       "      <td>146000.0</td>\n",
       "      <td>66.230000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200262002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>20037</td>\n",
       "      <td>2002</td>\n",
       "      <td>05/05/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>112 LAKE RD</td>\n",
       "      <td>0</td>\n",
       "      <td>129000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200372002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>20037</td>\n",
       "      <td>2002</td>\n",
       "      <td>05/05/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>112 LAKE RD</td>\n",
       "      <td>78400</td>\n",
       "      <td>129000.0</td>\n",
       "      <td>60.770000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200372002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>20037</td>\n",
       "      <td>2002</td>\n",
       "      <td>05/05/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>112 LAKE RD</td>\n",
       "      <td>0</td>\n",
       "      <td>129000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200372002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>20037</td>\n",
       "      <td>2002</td>\n",
       "      <td>05/05/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>112 LAKE RD</td>\n",
       "      <td>78400</td>\n",
       "      <td>129000.0</td>\n",
       "      <td>60.770000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200372002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69</td>\n",
       "      <td>20049</td>\n",
       "      <td>2002</td>\n",
       "      <td>06/18/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>13 CHESTER BRKS LN</td>\n",
       "      <td>55200</td>\n",
       "      <td>69900.0</td>\n",
       "      <td>78.969957</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200492002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>70</td>\n",
       "      <td>20049</td>\n",
       "      <td>2002</td>\n",
       "      <td>06/18/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>13 CHESTER BRKS LN</td>\n",
       "      <td>55200</td>\n",
       "      <td>69900.0</td>\n",
       "      <td>78.960000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200492002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69</td>\n",
       "      <td>20049</td>\n",
       "      <td>2002</td>\n",
       "      <td>06/18/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>13 CHESTER BRKS LN</td>\n",
       "      <td>55200</td>\n",
       "      <td>69900.0</td>\n",
       "      <td>78.969957</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200492002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>70</td>\n",
       "      <td>20049</td>\n",
       "      <td>2002</td>\n",
       "      <td>06/18/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>13 CHESTER BRKS LN</td>\n",
       "      <td>55200</td>\n",
       "      <td>69900.0</td>\n",
       "      <td>78.960000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200492002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>113</td>\n",
       "      <td>20047</td>\n",
       "      <td>2002</td>\n",
       "      <td>06/16/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>157 WALES RD</td>\n",
       "      <td>75100</td>\n",
       "      <td>116000.0</td>\n",
       "      <td>64.741379</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200472002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>114</td>\n",
       "      <td>20047</td>\n",
       "      <td>2002</td>\n",
       "      <td>06/16/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>157 WALES RD</td>\n",
       "      <td>75100</td>\n",
       "      <td>116000.0</td>\n",
       "      <td>64.740000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200472002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>113</td>\n",
       "      <td>20047</td>\n",
       "      <td>2002</td>\n",
       "      <td>06/16/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>157 WALES RD</td>\n",
       "      <td>75100</td>\n",
       "      <td>116000.0</td>\n",
       "      <td>64.741379</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200472002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>114</td>\n",
       "      <td>20047</td>\n",
       "      <td>2002</td>\n",
       "      <td>06/16/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>157 WALES RD</td>\n",
       "      <td>75100</td>\n",
       "      <td>116000.0</td>\n",
       "      <td>64.740000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200472002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>117</td>\n",
       "      <td>20001</td>\n",
       "      <td>2002</td>\n",
       "      <td>10/21/2002 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>16 CHESTER BROOKS LN</td>\n",
       "      <td>203300</td>\n",
       "      <td>340912.0</td>\n",
       "      <td>59.634158</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200012002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>118</td>\n",
       "      <td>20001</td>\n",
       "      <td>2002</td>\n",
       "      <td>10/21/2002 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>16 CHESTER BROOKS LN</td>\n",
       "      <td>203300</td>\n",
       "      <td>340912.0</td>\n",
       "      <td>59.630000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200012002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>117</td>\n",
       "      <td>20001</td>\n",
       "      <td>2002</td>\n",
       "      <td>10/21/2002 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>16 CHESTER BROOKS LN</td>\n",
       "      <td>203300</td>\n",
       "      <td>340912.0</td>\n",
       "      <td>59.634158</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200012002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>118</td>\n",
       "      <td>20001</td>\n",
       "      <td>2002</td>\n",
       "      <td>10/21/2002 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>16 CHESTER BROOKS LN</td>\n",
       "      <td>203300</td>\n",
       "      <td>340912.0</td>\n",
       "      <td>59.630000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200012002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150</td>\n",
       "      <td>20039</td>\n",
       "      <td>2002</td>\n",
       "      <td>05/19/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>176 HEBRON RD</td>\n",
       "      <td>71000</td>\n",
       "      <td>218000.0</td>\n",
       "      <td>32.568807</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200392002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>151</td>\n",
       "      <td>20039</td>\n",
       "      <td>2002</td>\n",
       "      <td>05/19/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>176 HEBRON RD</td>\n",
       "      <td>71000</td>\n",
       "      <td>218000.0</td>\n",
       "      <td>32.560000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200392002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150</td>\n",
       "      <td>20039</td>\n",
       "      <td>2002</td>\n",
       "      <td>05/19/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>176 HEBRON RD</td>\n",
       "      <td>71000</td>\n",
       "      <td>218000.0</td>\n",
       "      <td>32.568807</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200392002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>151</td>\n",
       "      <td>20039</td>\n",
       "      <td>2002</td>\n",
       "      <td>05/19/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>176 HEBRON RD</td>\n",
       "      <td>71000</td>\n",
       "      <td>218000.0</td>\n",
       "      <td>32.560000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200392002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>164</td>\n",
       "      <td>20008</td>\n",
       "      <td>2002</td>\n",
       "      <td>12/02/2002 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>187 BOSTON HL RD</td>\n",
       "      <td>118700</td>\n",
       "      <td>219900.0</td>\n",
       "      <td>53.979081</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200082002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>165</td>\n",
       "      <td>20008</td>\n",
       "      <td>2002</td>\n",
       "      <td>12/02/2002 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>187 BOSTON HL RD</td>\n",
       "      <td>118700</td>\n",
       "      <td>219900.0</td>\n",
       "      <td>53.970000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200082002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>619</td>\n",
       "      <td>20006</td>\n",
       "      <td>2002</td>\n",
       "      <td>11/07/2002 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>KINGSLEY DR</td>\n",
       "      <td>592000</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>65.777778</td>\n",
       "      <td>Apartments</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200062002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>620</td>\n",
       "      <td>20006</td>\n",
       "      <td>2002</td>\n",
       "      <td>11/07/2002 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>KINGSLEY DR</td>\n",
       "      <td>592000</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>65.770000</td>\n",
       "      <td>Apartments</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200062002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>621</td>\n",
       "      <td>20018</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/10/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>LAKE RD</td>\n",
       "      <td>3200</td>\n",
       "      <td>5100.0</td>\n",
       "      <td>62.745098</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200182002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>627</td>\n",
       "      <td>20018</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/10/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>LAKE RD</td>\n",
       "      <td>3200</td>\n",
       "      <td>5100.0</td>\n",
       "      <td>62.740000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200182002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>622</td>\n",
       "      <td>20019</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/10/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>LAKE RD</td>\n",
       "      <td>44000</td>\n",
       "      <td>42500.0</td>\n",
       "      <td>103.529412</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200192002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>628</td>\n",
       "      <td>20019</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/10/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>LAKE RD</td>\n",
       "      <td>44000</td>\n",
       "      <td>42500.0</td>\n",
       "      <td>103.520000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200192002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>621</td>\n",
       "      <td>20018</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/10/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>LAKE RD</td>\n",
       "      <td>3200</td>\n",
       "      <td>5100.0</td>\n",
       "      <td>62.745098</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200182002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>627</td>\n",
       "      <td>20018</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/10/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>LAKE RD</td>\n",
       "      <td>3200</td>\n",
       "      <td>5100.0</td>\n",
       "      <td>62.740000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200182002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>622</td>\n",
       "      <td>20019</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/10/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>LAKE RD</td>\n",
       "      <td>44000</td>\n",
       "      <td>42500.0</td>\n",
       "      <td>103.529412</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200192002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>628</td>\n",
       "      <td>20019</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/10/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>LAKE RD</td>\n",
       "      <td>44000</td>\n",
       "      <td>42500.0</td>\n",
       "      <td>103.520000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200192002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>651</td>\n",
       "      <td>20032</td>\n",
       "      <td>2002</td>\n",
       "      <td>04/25/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>LT 1 RT 6</td>\n",
       "      <td>32000</td>\n",
       "      <td>34500.0</td>\n",
       "      <td>92.753623</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200322002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>652</td>\n",
       "      <td>20032</td>\n",
       "      <td>2002</td>\n",
       "      <td>04/25/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>LT 1 RT 6</td>\n",
       "      <td>32000</td>\n",
       "      <td>34500.0</td>\n",
       "      <td>92.750000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200322002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>651</td>\n",
       "      <td>20032</td>\n",
       "      <td>2002</td>\n",
       "      <td>04/25/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>LT 1 RT 6</td>\n",
       "      <td>32000</td>\n",
       "      <td>34500.0</td>\n",
       "      <td>92.753623</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200322002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>652</td>\n",
       "      <td>20032</td>\n",
       "      <td>2002</td>\n",
       "      <td>04/25/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>LT 1 RT 6</td>\n",
       "      <td>32000</td>\n",
       "      <td>34500.0</td>\n",
       "      <td>92.750000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200322002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>653</td>\n",
       "      <td>20016</td>\n",
       "      <td>2002</td>\n",
       "      <td>01/21/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>OLD FARMS RD</td>\n",
       "      <td>42400</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>67.301587</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200162002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>656</td>\n",
       "      <td>20016</td>\n",
       "      <td>2002</td>\n",
       "      <td>01/21/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>OLD FARMS RD</td>\n",
       "      <td>42400</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>67.300000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200162002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>653</td>\n",
       "      <td>20016</td>\n",
       "      <td>2002</td>\n",
       "      <td>01/21/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>OLD FARMS RD</td>\n",
       "      <td>42400</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>67.301587</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200162002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>656</td>\n",
       "      <td>20016</td>\n",
       "      <td>2002</td>\n",
       "      <td>01/21/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>OLD FARMS RD</td>\n",
       "      <td>42400</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>67.300000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200162002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>670</td>\n",
       "      <td>20068</td>\n",
       "      <td>2002</td>\n",
       "      <td>06/03/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>WEST ST</td>\n",
       "      <td>0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200682002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>674</td>\n",
       "      <td>20068</td>\n",
       "      <td>2002</td>\n",
       "      <td>06/03/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>WEST ST</td>\n",
       "      <td>0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200682002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>671</td>\n",
       "      <td>20022</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/13/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>WEST ST</td>\n",
       "      <td>49300</td>\n",
       "      <td>50269.0</td>\n",
       "      <td>98.072371</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200222002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>675</td>\n",
       "      <td>20022</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/13/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>WEST ST</td>\n",
       "      <td>49300</td>\n",
       "      <td>50269.0</td>\n",
       "      <td>98.070000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200222002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>672</td>\n",
       "      <td>20023</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/13/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>WEST ST</td>\n",
       "      <td>49300</td>\n",
       "      <td>50269.0</td>\n",
       "      <td>98.072371</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200232002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>676</td>\n",
       "      <td>20023</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/13/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>WEST ST</td>\n",
       "      <td>49300</td>\n",
       "      <td>50269.0</td>\n",
       "      <td>98.070000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200232002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>670</td>\n",
       "      <td>20068</td>\n",
       "      <td>2002</td>\n",
       "      <td>06/03/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>WEST ST</td>\n",
       "      <td>0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200682002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>674</td>\n",
       "      <td>20068</td>\n",
       "      <td>2002</td>\n",
       "      <td>06/03/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>WEST ST</td>\n",
       "      <td>0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200682002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>671</td>\n",
       "      <td>20022</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/13/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>WEST ST</td>\n",
       "      <td>49300</td>\n",
       "      <td>50269.0</td>\n",
       "      <td>98.072371</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200222002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>675</td>\n",
       "      <td>20022</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/13/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>WEST ST</td>\n",
       "      <td>49300</td>\n",
       "      <td>50269.0</td>\n",
       "      <td>98.070000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200222002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>672</td>\n",
       "      <td>20023</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/13/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>WEST ST</td>\n",
       "      <td>49300</td>\n",
       "      <td>50269.0</td>\n",
       "      <td>98.072371</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200232002Andover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>676</td>\n",
       "      <td>20023</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/13/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>WEST ST</td>\n",
       "      <td>49300</td>\n",
       "      <td>50269.0</td>\n",
       "      <td>98.070000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200232002Andover</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID SerialNumber ListYear            DateRecorded     Town  \\\n",
       "5      6        20030     2002  04/24/2003 12:00:00 AM  Andover   \n",
       "6      7        20030     2002  04/24/2003 12:00:00 AM  Andover   \n",
       "5      6        20030     2002  04/24/2003 12:00:00 AM  Andover   \n",
       "6      7        20030     2002  04/24/2003 12:00:00 AM  Andover   \n",
       "22    23        20026     2002  03/04/2003 12:00:00 AM  Andover   \n",
       "23    24        20026     2002  03/04/2003 12:00:00 AM  Andover   \n",
       "22    23        20026     2002  03/04/2003 12:00:00 AM  Andover   \n",
       "23    24        20026     2002  03/04/2003 12:00:00 AM  Andover   \n",
       "33    34        20037     2002  05/05/2003 12:00:00 AM  Andover   \n",
       "34    35        20037     2002  05/05/2003 12:00:00 AM  Andover   \n",
       "33    34        20037     2002  05/05/2003 12:00:00 AM  Andover   \n",
       "34    35        20037     2002  05/05/2003 12:00:00 AM  Andover   \n",
       "68    69        20049     2002  06/18/2003 12:00:00 AM  Andover   \n",
       "69    70        20049     2002  06/18/2003 12:00:00 AM  Andover   \n",
       "68    69        20049     2002  06/18/2003 12:00:00 AM  Andover   \n",
       "69    70        20049     2002  06/18/2003 12:00:00 AM  Andover   \n",
       "112  113        20047     2002  06/16/2003 12:00:00 AM  Andover   \n",
       "113  114        20047     2002  06/16/2003 12:00:00 AM  Andover   \n",
       "112  113        20047     2002  06/16/2003 12:00:00 AM  Andover   \n",
       "113  114        20047     2002  06/16/2003 12:00:00 AM  Andover   \n",
       "116  117        20001     2002  10/21/2002 12:00:00 AM  Andover   \n",
       "117  118        20001     2002  10/21/2002 12:00:00 AM  Andover   \n",
       "116  117        20001     2002  10/21/2002 12:00:00 AM  Andover   \n",
       "117  118        20001     2002  10/21/2002 12:00:00 AM  Andover   \n",
       "149  150        20039     2002  05/19/2003 12:00:00 AM  Andover   \n",
       "150  151        20039     2002  05/19/2003 12:00:00 AM  Andover   \n",
       "149  150        20039     2002  05/19/2003 12:00:00 AM  Andover   \n",
       "150  151        20039     2002  05/19/2003 12:00:00 AM  Andover   \n",
       "163  164        20008     2002  12/02/2002 12:00:00 AM  Andover   \n",
       "164  165        20008     2002  12/02/2002 12:00:00 AM  Andover   \n",
       "..   ...          ...      ...                     ...      ...   \n",
       "618  619        20006     2002  11/07/2002 12:00:00 AM  Andover   \n",
       "619  620        20006     2002  11/07/2002 12:00:00 AM  Andover   \n",
       "620  621        20018     2002  02/10/2003 12:00:00 AM  Andover   \n",
       "626  627        20018     2002  02/10/2003 12:00:00 AM  Andover   \n",
       "621  622        20019     2002  02/10/2003 12:00:00 AM  Andover   \n",
       "627  628        20019     2002  02/10/2003 12:00:00 AM  Andover   \n",
       "620  621        20018     2002  02/10/2003 12:00:00 AM  Andover   \n",
       "626  627        20018     2002  02/10/2003 12:00:00 AM  Andover   \n",
       "621  622        20019     2002  02/10/2003 12:00:00 AM  Andover   \n",
       "627  628        20019     2002  02/10/2003 12:00:00 AM  Andover   \n",
       "650  651        20032     2002  04/25/2003 12:00:00 AM  Andover   \n",
       "651  652        20032     2002  04/25/2003 12:00:00 AM  Andover   \n",
       "650  651        20032     2002  04/25/2003 12:00:00 AM  Andover   \n",
       "651  652        20032     2002  04/25/2003 12:00:00 AM  Andover   \n",
       "652  653        20016     2002  01/21/2003 12:00:00 AM  Andover   \n",
       "655  656        20016     2002  01/21/2003 12:00:00 AM  Andover   \n",
       "652  653        20016     2002  01/21/2003 12:00:00 AM  Andover   \n",
       "655  656        20016     2002  01/21/2003 12:00:00 AM  Andover   \n",
       "669  670        20068     2002  06/03/2003 12:00:00 AM  Andover   \n",
       "673  674        20068     2002  06/03/2003 12:00:00 AM  Andover   \n",
       "670  671        20022     2002  02/13/2003 12:00:00 AM  Andover   \n",
       "674  675        20022     2002  02/13/2003 12:00:00 AM  Andover   \n",
       "671  672        20023     2002  02/13/2003 12:00:00 AM  Andover   \n",
       "675  676        20023     2002  02/13/2003 12:00:00 AM  Andover   \n",
       "669  670        20068     2002  06/03/2003 12:00:00 AM  Andover   \n",
       "673  674        20068     2002  06/03/2003 12:00:00 AM  Andover   \n",
       "670  671        20022     2002  02/13/2003 12:00:00 AM  Andover   \n",
       "674  675        20022     2002  02/13/2003 12:00:00 AM  Andover   \n",
       "671  672        20023     2002  02/13/2003 12:00:00 AM  Andover   \n",
       "675  676        20023     2002  02/13/2003 12:00:00 AM  Andover   \n",
       "\n",
       "                  Address  AssessedValue  SaleAmount  SalesRatio PropertyType  \\\n",
       "5           10 BAUSOLA RD          91800    189900.0   48.341232  Residential   \n",
       "6           10 BAUSOLA RD          91800    189900.0   48.340000  Residential   \n",
       "5           10 BAUSOLA RD          91800    189900.0   48.341232  Residential   \n",
       "6           10 BAUSOLA RD          91800    189900.0   48.340000  Residential   \n",
       "22        109 LAKESIDE DR          96700    146000.0   66.232877  Residential   \n",
       "23        109 LAKESIDE DR          96700    146000.0   66.230000  Residential   \n",
       "22        109 LAKESIDE DR          96700    146000.0   66.232877  Residential   \n",
       "23        109 LAKESIDE DR          96700    146000.0   66.230000  Residential   \n",
       "33            112 LAKE RD              0    129000.0    0.000000  Residential   \n",
       "34            112 LAKE RD          78400    129000.0   60.770000  Residential   \n",
       "33            112 LAKE RD              0    129000.0    0.000000  Residential   \n",
       "34            112 LAKE RD          78400    129000.0   60.770000  Residential   \n",
       "68     13 CHESTER BRKS LN          55200     69900.0   78.969957  Vacant Land   \n",
       "69     13 CHESTER BRKS LN          55200     69900.0   78.960000  Vacant Land   \n",
       "68     13 CHESTER BRKS LN          55200     69900.0   78.969957  Vacant Land   \n",
       "69     13 CHESTER BRKS LN          55200     69900.0   78.960000  Vacant Land   \n",
       "112          157 WALES RD          75100    116000.0   64.741379  Residential   \n",
       "113          157 WALES RD          75100    116000.0   64.740000  Residential   \n",
       "112          157 WALES RD          75100    116000.0   64.741379  Residential   \n",
       "113          157 WALES RD          75100    116000.0   64.740000  Residential   \n",
       "116  16 CHESTER BROOKS LN         203300    340912.0   59.634158  Residential   \n",
       "117  16 CHESTER BROOKS LN         203300    340912.0   59.630000  Residential   \n",
       "116  16 CHESTER BROOKS LN         203300    340912.0   59.634158  Residential   \n",
       "117  16 CHESTER BROOKS LN         203300    340912.0   59.630000  Residential   \n",
       "149         176 HEBRON RD          71000    218000.0   32.568807  Residential   \n",
       "150         176 HEBRON RD          71000    218000.0   32.560000  Residential   \n",
       "149         176 HEBRON RD          71000    218000.0   32.568807  Residential   \n",
       "150         176 HEBRON RD          71000    218000.0   32.560000  Residential   \n",
       "163      187 BOSTON HL RD         118700    219900.0   53.979081  Residential   \n",
       "164      187 BOSTON HL RD         118700    219900.0   53.970000  Residential   \n",
       "..                    ...            ...         ...         ...          ...   \n",
       "618           KINGSLEY DR         592000    900000.0   65.777778   Apartments   \n",
       "619           KINGSLEY DR         592000    900000.0   65.770000   Apartments   \n",
       "620               LAKE RD           3200      5100.0   62.745098  Vacant Land   \n",
       "626               LAKE RD           3200      5100.0   62.740000  Vacant Land   \n",
       "621               LAKE RD          44000     42500.0  103.529412  Vacant Land   \n",
       "627               LAKE RD          44000     42500.0  103.520000  Vacant Land   \n",
       "620               LAKE RD           3200      5100.0   62.745098  Vacant Land   \n",
       "626               LAKE RD           3200      5100.0   62.740000  Vacant Land   \n",
       "621               LAKE RD          44000     42500.0  103.529412  Vacant Land   \n",
       "627               LAKE RD          44000     42500.0  103.520000  Vacant Land   \n",
       "650             LT 1 RT 6          32000     34500.0   92.753623  Vacant Land   \n",
       "651             LT 1 RT 6          32000     34500.0   92.750000  Vacant Land   \n",
       "650             LT 1 RT 6          32000     34500.0   92.753623  Vacant Land   \n",
       "651             LT 1 RT 6          32000     34500.0   92.750000  Vacant Land   \n",
       "652          OLD FARMS RD          42400     63000.0   67.301587  Vacant Land   \n",
       "655          OLD FARMS RD          42400     63000.0   67.300000  Vacant Land   \n",
       "652          OLD FARMS RD          42400     63000.0   67.301587  Vacant Land   \n",
       "655          OLD FARMS RD          42400     63000.0   67.300000  Vacant Land   \n",
       "669               WEST ST              0      5000.0    0.000000  Vacant Land   \n",
       "673               WEST ST              0      5000.0    0.000000  Vacant Land   \n",
       "670               WEST ST          49300     50269.0   98.072371  Vacant Land   \n",
       "674               WEST ST          49300     50269.0   98.070000  Vacant Land   \n",
       "671               WEST ST          49300     50269.0   98.072371  Vacant Land   \n",
       "675               WEST ST          49300     50269.0   98.070000  Vacant Land   \n",
       "669               WEST ST              0      5000.0    0.000000  Vacant Land   \n",
       "673               WEST ST              0      5000.0    0.000000  Vacant Land   \n",
       "670               WEST ST          49300     50269.0   98.072371  Vacant Land   \n",
       "674               WEST ST          49300     50269.0   98.070000  Vacant Land   \n",
       "671               WEST ST          49300     50269.0   98.072371  Vacant Land   \n",
       "675               WEST ST          49300     50269.0   98.070000  Vacant Land   \n",
       "\n",
       "    ResidentialType NonUseCode Remarks       duplication  \n",
       "5     Single Family          0     NaN  200302002Andover  \n",
       "6     Single Family          0     NaN  200302002Andover  \n",
       "5     Single Family          0     NaN  200302002Andover  \n",
       "6     Single Family          0     NaN  200302002Andover  \n",
       "22    Single Family          0     NaN  200262002Andover  \n",
       "23    Single Family          0     NaN  200262002Andover  \n",
       "22    Single Family          0     NaN  200262002Andover  \n",
       "23    Single Family          0     NaN  200262002Andover  \n",
       "33    Single Family          0     NaN  200372002Andover  \n",
       "34    Single Family          0     NaN  200372002Andover  \n",
       "33    Single Family          0     NaN  200372002Andover  \n",
       "34    Single Family          0     NaN  200372002Andover  \n",
       "68              NaN          0     NaN  200492002Andover  \n",
       "69              NaN          0     NaN  200492002Andover  \n",
       "68              NaN          0     NaN  200492002Andover  \n",
       "69              NaN          0     NaN  200492002Andover  \n",
       "112   Single Family          0     NaN  200472002Andover  \n",
       "113   Single Family          0     NaN  200472002Andover  \n",
       "112   Single Family          0     NaN  200472002Andover  \n",
       "113   Single Family          0     NaN  200472002Andover  \n",
       "116   Single Family          0     NaN  200012002Andover  \n",
       "117   Single Family          0     NaN  200012002Andover  \n",
       "116   Single Family          0     NaN  200012002Andover  \n",
       "117   Single Family          0     NaN  200012002Andover  \n",
       "149   Single Family          7     NaN  200392002Andover  \n",
       "150   Single Family          7     NaN  200392002Andover  \n",
       "149   Single Family          7     NaN  200392002Andover  \n",
       "150   Single Family          7     NaN  200392002Andover  \n",
       "163   Single Family          0     NaN  200082002Andover  \n",
       "164   Single Family          0     NaN  200082002Andover  \n",
       "..              ...        ...     ...               ...  \n",
       "618             NaN          0     NaN  200062002Andover  \n",
       "619             NaN          0     NaN  200062002Andover  \n",
       "620             NaN         12     NaN  200182002Andover  \n",
       "626             NaN         12     NaN  200182002Andover  \n",
       "621             NaN          0     NaN  200192002Andover  \n",
       "627             NaN          6     NaN  200192002Andover  \n",
       "620             NaN         12     NaN  200182002Andover  \n",
       "626             NaN         12     NaN  200182002Andover  \n",
       "621             NaN          0     NaN  200192002Andover  \n",
       "627             NaN          6     NaN  200192002Andover  \n",
       "650             NaN         14     NaN  200322002Andover  \n",
       "651             NaN         14     NaN  200322002Andover  \n",
       "650             NaN         14     NaN  200322002Andover  \n",
       "651             NaN         14     NaN  200322002Andover  \n",
       "652             NaN          0     NaN  200162002Andover  \n",
       "655             NaN          0     NaN  200162002Andover  \n",
       "652             NaN          0     NaN  200162002Andover  \n",
       "655             NaN          0     NaN  200162002Andover  \n",
       "669             NaN         17     NaN  200682002Andover  \n",
       "673             NaN         17     NaN  200682002Andover  \n",
       "670             NaN         17     NaN  200222002Andover  \n",
       "674             NaN         17     NaN  200222002Andover  \n",
       "671             NaN         17     NaN  200232002Andover  \n",
       "675             NaN         17     NaN  200232002Andover  \n",
       "669             NaN         17     NaN  200682002Andover  \n",
       "673             NaN         17     NaN  200682002Andover  \n",
       "670             NaN         17     NaN  200222002Andover  \n",
       "674             NaN         17     NaN  200222002Andover  \n",
       "671             NaN         17     NaN  200232002Andover  \n",
       "675             NaN         17     NaN  200232002Andover  \n",
       "\n",
       "[272 rows x 14 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identify_duplicate_rows(sp, sp_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_raw = sample_raw_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all cleans that come before removing duplicates\n",
    "sp = trim_whitespace(sp_raw, 'Town')\n",
    "sp = trim_whitespace(sp, 'Address')\n",
    "sp = convert_address_street_abbreviations(sp, street_conversions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of sp before removing duplicates: 2000\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of sp before removing duplicates: \" + str(len(sp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = remove_duplicate_rows(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of sp after removing duplicates: 1932\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of sp after removing duplicates: \" + str(len(sp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 272\n",
      "False\n",
      "1864.0\n"
     ]
    }
   ],
   "source": [
    "dupes = identify_duplicate_rows(sp, new_sample)\n",
    "print(\"Number of duplicate rows: \" + str(len(dupes)))\n",
    "print(len(sp) == len(sp_raw) - len(dupes) / 2)\n",
    "print(len(sp_raw) - len(dupes) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SerialNumber</th>\n",
       "      <th>ListYear</th>\n",
       "      <th>DateRecorded</th>\n",
       "      <th>Town</th>\n",
       "      <th>Address</th>\n",
       "      <th>AssessedValue</th>\n",
       "      <th>SaleAmount</th>\n",
       "      <th>SalesRatio</th>\n",
       "      <th>PropertyType</th>\n",
       "      <th>ResidentialType</th>\n",
       "      <th>NonUseCode</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>20030</td>\n",
       "      <td>2002</td>\n",
       "      <td>04/24/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>10 BAUSOLA RD</td>\n",
       "      <td>91800</td>\n",
       "      <td>189900.0</td>\n",
       "      <td>48.341232</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>20030</td>\n",
       "      <td>2002</td>\n",
       "      <td>04/24/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>10 BAUSOLA RD</td>\n",
       "      <td>91800</td>\n",
       "      <td>189900.0</td>\n",
       "      <td>48.340000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>20030</td>\n",
       "      <td>2002</td>\n",
       "      <td>04/24/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>10 BAUSOLA RD</td>\n",
       "      <td>91800</td>\n",
       "      <td>189900.0</td>\n",
       "      <td>48.341232</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>20030</td>\n",
       "      <td>2002</td>\n",
       "      <td>04/24/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>10 BAUSOLA RD</td>\n",
       "      <td>91800</td>\n",
       "      <td>189900.0</td>\n",
       "      <td>48.340000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>20026</td>\n",
       "      <td>2002</td>\n",
       "      <td>03/04/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>109 LAKESIDE DR</td>\n",
       "      <td>96700</td>\n",
       "      <td>146000.0</td>\n",
       "      <td>66.232877</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "      <td>20026</td>\n",
       "      <td>2002</td>\n",
       "      <td>03/04/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>109 LAKESIDE DR</td>\n",
       "      <td>96700</td>\n",
       "      <td>146000.0</td>\n",
       "      <td>66.230000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23</td>\n",
       "      <td>20026</td>\n",
       "      <td>2002</td>\n",
       "      <td>03/04/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>109 LAKESIDE DR</td>\n",
       "      <td>96700</td>\n",
       "      <td>146000.0</td>\n",
       "      <td>66.232877</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24</td>\n",
       "      <td>20026</td>\n",
       "      <td>2002</td>\n",
       "      <td>03/04/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>109 LAKESIDE DR</td>\n",
       "      <td>96700</td>\n",
       "      <td>146000.0</td>\n",
       "      <td>66.230000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34</td>\n",
       "      <td>20037</td>\n",
       "      <td>2002</td>\n",
       "      <td>05/05/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>112 LAKE RD</td>\n",
       "      <td>0</td>\n",
       "      <td>129000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>35</td>\n",
       "      <td>20037</td>\n",
       "      <td>2002</td>\n",
       "      <td>05/05/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>112 LAKE RD</td>\n",
       "      <td>78400</td>\n",
       "      <td>129000.0</td>\n",
       "      <td>60.770000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>34</td>\n",
       "      <td>20037</td>\n",
       "      <td>2002</td>\n",
       "      <td>05/05/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>112 LAKE RD</td>\n",
       "      <td>0</td>\n",
       "      <td>129000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>35</td>\n",
       "      <td>20037</td>\n",
       "      <td>2002</td>\n",
       "      <td>05/05/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>112 LAKE RD</td>\n",
       "      <td>78400</td>\n",
       "      <td>129000.0</td>\n",
       "      <td>60.770000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>69</td>\n",
       "      <td>20049</td>\n",
       "      <td>2002</td>\n",
       "      <td>06/18/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>13 CHESTER BRKS LN</td>\n",
       "      <td>55200</td>\n",
       "      <td>69900.0</td>\n",
       "      <td>78.969957</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>70</td>\n",
       "      <td>20049</td>\n",
       "      <td>2002</td>\n",
       "      <td>06/18/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>13 CHESTER BRKS LN</td>\n",
       "      <td>55200</td>\n",
       "      <td>69900.0</td>\n",
       "      <td>78.960000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>69</td>\n",
       "      <td>20049</td>\n",
       "      <td>2002</td>\n",
       "      <td>06/18/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>13 CHESTER BRKS LN</td>\n",
       "      <td>55200</td>\n",
       "      <td>69900.0</td>\n",
       "      <td>78.969957</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>70</td>\n",
       "      <td>20049</td>\n",
       "      <td>2002</td>\n",
       "      <td>06/18/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>13 CHESTER BRKS LN</td>\n",
       "      <td>55200</td>\n",
       "      <td>69900.0</td>\n",
       "      <td>78.960000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>113</td>\n",
       "      <td>20047</td>\n",
       "      <td>2002</td>\n",
       "      <td>06/16/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>157 WALES RD</td>\n",
       "      <td>75100</td>\n",
       "      <td>116000.0</td>\n",
       "      <td>64.741379</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>114</td>\n",
       "      <td>20047</td>\n",
       "      <td>2002</td>\n",
       "      <td>06/16/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>157 WALES RD</td>\n",
       "      <td>75100</td>\n",
       "      <td>116000.0</td>\n",
       "      <td>64.740000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>113</td>\n",
       "      <td>20047</td>\n",
       "      <td>2002</td>\n",
       "      <td>06/16/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>157 WALES RD</td>\n",
       "      <td>75100</td>\n",
       "      <td>116000.0</td>\n",
       "      <td>64.741379</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>114</td>\n",
       "      <td>20047</td>\n",
       "      <td>2002</td>\n",
       "      <td>06/16/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>157 WALES RD</td>\n",
       "      <td>75100</td>\n",
       "      <td>116000.0</td>\n",
       "      <td>64.740000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>117</td>\n",
       "      <td>20001</td>\n",
       "      <td>2002</td>\n",
       "      <td>10/21/2002 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>16 CHESTER BROOKS LN</td>\n",
       "      <td>203300</td>\n",
       "      <td>340912.0</td>\n",
       "      <td>59.634158</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>118</td>\n",
       "      <td>20001</td>\n",
       "      <td>2002</td>\n",
       "      <td>10/21/2002 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>16 CHESTER BROOKS LN</td>\n",
       "      <td>203300</td>\n",
       "      <td>340912.0</td>\n",
       "      <td>59.630000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>117</td>\n",
       "      <td>20001</td>\n",
       "      <td>2002</td>\n",
       "      <td>10/21/2002 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>16 CHESTER BROOKS LN</td>\n",
       "      <td>203300</td>\n",
       "      <td>340912.0</td>\n",
       "      <td>59.634158</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>118</td>\n",
       "      <td>20001</td>\n",
       "      <td>2002</td>\n",
       "      <td>10/21/2002 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>16 CHESTER BROOKS LN</td>\n",
       "      <td>203300</td>\n",
       "      <td>340912.0</td>\n",
       "      <td>59.630000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>150</td>\n",
       "      <td>20039</td>\n",
       "      <td>2002</td>\n",
       "      <td>05/19/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>176 HEBRON RD</td>\n",
       "      <td>71000</td>\n",
       "      <td>218000.0</td>\n",
       "      <td>32.568807</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>151</td>\n",
       "      <td>20039</td>\n",
       "      <td>2002</td>\n",
       "      <td>05/19/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>176 HEBRON RD</td>\n",
       "      <td>71000</td>\n",
       "      <td>218000.0</td>\n",
       "      <td>32.560000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>150</td>\n",
       "      <td>20039</td>\n",
       "      <td>2002</td>\n",
       "      <td>05/19/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>176 HEBRON RD</td>\n",
       "      <td>71000</td>\n",
       "      <td>218000.0</td>\n",
       "      <td>32.568807</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>151</td>\n",
       "      <td>20039</td>\n",
       "      <td>2002</td>\n",
       "      <td>05/19/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>176 HEBRON RD</td>\n",
       "      <td>71000</td>\n",
       "      <td>218000.0</td>\n",
       "      <td>32.560000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>164</td>\n",
       "      <td>20008</td>\n",
       "      <td>2002</td>\n",
       "      <td>12/02/2002 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>187 BOSTON HL RD</td>\n",
       "      <td>118700</td>\n",
       "      <td>219900.0</td>\n",
       "      <td>53.979081</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>165</td>\n",
       "      <td>20008</td>\n",
       "      <td>2002</td>\n",
       "      <td>12/02/2002 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>187 BOSTON HL RD</td>\n",
       "      <td>118700</td>\n",
       "      <td>219900.0</td>\n",
       "      <td>53.970000</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>619</td>\n",
       "      <td>20006</td>\n",
       "      <td>2002</td>\n",
       "      <td>11/07/2002 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>KINGSLEY DR</td>\n",
       "      <td>592000</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>65.777778</td>\n",
       "      <td>Apartments</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>620</td>\n",
       "      <td>20006</td>\n",
       "      <td>2002</td>\n",
       "      <td>11/07/2002 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>KINGSLEY DR</td>\n",
       "      <td>592000</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>65.770000</td>\n",
       "      <td>Apartments</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>621</td>\n",
       "      <td>20018</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/10/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>LAKE RD</td>\n",
       "      <td>3200</td>\n",
       "      <td>5100.0</td>\n",
       "      <td>62.745098</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>627</td>\n",
       "      <td>20018</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/10/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>LAKE RD</td>\n",
       "      <td>3200</td>\n",
       "      <td>5100.0</td>\n",
       "      <td>62.740000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>622</td>\n",
       "      <td>20019</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/10/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>LAKE RD</td>\n",
       "      <td>44000</td>\n",
       "      <td>42500.0</td>\n",
       "      <td>103.529412</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>628</td>\n",
       "      <td>20019</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/10/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>LAKE RD</td>\n",
       "      <td>44000</td>\n",
       "      <td>42500.0</td>\n",
       "      <td>103.520000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>621</td>\n",
       "      <td>20018</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/10/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>LAKE RD</td>\n",
       "      <td>3200</td>\n",
       "      <td>5100.0</td>\n",
       "      <td>62.745098</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>627</td>\n",
       "      <td>20018</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/10/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>LAKE RD</td>\n",
       "      <td>3200</td>\n",
       "      <td>5100.0</td>\n",
       "      <td>62.740000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>622</td>\n",
       "      <td>20019</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/10/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>LAKE RD</td>\n",
       "      <td>44000</td>\n",
       "      <td>42500.0</td>\n",
       "      <td>103.529412</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>628</td>\n",
       "      <td>20019</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/10/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>LAKE RD</td>\n",
       "      <td>44000</td>\n",
       "      <td>42500.0</td>\n",
       "      <td>103.520000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>651</td>\n",
       "      <td>20032</td>\n",
       "      <td>2002</td>\n",
       "      <td>04/25/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>LT 1 RT 6</td>\n",
       "      <td>32000</td>\n",
       "      <td>34500.0</td>\n",
       "      <td>92.753623</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>652</td>\n",
       "      <td>20032</td>\n",
       "      <td>2002</td>\n",
       "      <td>04/25/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>LT 1 RT 6</td>\n",
       "      <td>32000</td>\n",
       "      <td>34500.0</td>\n",
       "      <td>92.750000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>651</td>\n",
       "      <td>20032</td>\n",
       "      <td>2002</td>\n",
       "      <td>04/25/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>LT 1 RT 6</td>\n",
       "      <td>32000</td>\n",
       "      <td>34500.0</td>\n",
       "      <td>92.753623</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>652</td>\n",
       "      <td>20032</td>\n",
       "      <td>2002</td>\n",
       "      <td>04/25/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>LT 1 RT 6</td>\n",
       "      <td>32000</td>\n",
       "      <td>34500.0</td>\n",
       "      <td>92.750000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>653</td>\n",
       "      <td>20016</td>\n",
       "      <td>2002</td>\n",
       "      <td>01/21/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>OLD FARMS RD</td>\n",
       "      <td>42400</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>67.301587</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>656</td>\n",
       "      <td>20016</td>\n",
       "      <td>2002</td>\n",
       "      <td>01/21/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>OLD FARMS RD</td>\n",
       "      <td>42400</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>67.300000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>653</td>\n",
       "      <td>20016</td>\n",
       "      <td>2002</td>\n",
       "      <td>01/21/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>OLD FARMS RD</td>\n",
       "      <td>42400</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>67.301587</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>656</td>\n",
       "      <td>20016</td>\n",
       "      <td>2002</td>\n",
       "      <td>01/21/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>OLD FARMS RD</td>\n",
       "      <td>42400</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>67.300000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>670</td>\n",
       "      <td>20068</td>\n",
       "      <td>2002</td>\n",
       "      <td>06/03/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>WEST ST</td>\n",
       "      <td>0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>674</td>\n",
       "      <td>20068</td>\n",
       "      <td>2002</td>\n",
       "      <td>06/03/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>WEST ST</td>\n",
       "      <td>0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>671</td>\n",
       "      <td>20022</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/13/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>WEST ST</td>\n",
       "      <td>49300</td>\n",
       "      <td>50269.0</td>\n",
       "      <td>98.072371</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>675</td>\n",
       "      <td>20022</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/13/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>WEST ST</td>\n",
       "      <td>49300</td>\n",
       "      <td>50269.0</td>\n",
       "      <td>98.070000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>672</td>\n",
       "      <td>20023</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/13/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>WEST ST</td>\n",
       "      <td>49300</td>\n",
       "      <td>50269.0</td>\n",
       "      <td>98.072371</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>676</td>\n",
       "      <td>20023</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/13/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>WEST ST</td>\n",
       "      <td>49300</td>\n",
       "      <td>50269.0</td>\n",
       "      <td>98.070000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>670</td>\n",
       "      <td>20068</td>\n",
       "      <td>2002</td>\n",
       "      <td>06/03/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>WEST ST</td>\n",
       "      <td>0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>674</td>\n",
       "      <td>20068</td>\n",
       "      <td>2002</td>\n",
       "      <td>06/03/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>WEST ST</td>\n",
       "      <td>0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>671</td>\n",
       "      <td>20022</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/13/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>WEST ST</td>\n",
       "      <td>49300</td>\n",
       "      <td>50269.0</td>\n",
       "      <td>98.072371</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>675</td>\n",
       "      <td>20022</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/13/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>WEST ST</td>\n",
       "      <td>49300</td>\n",
       "      <td>50269.0</td>\n",
       "      <td>98.070000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>672</td>\n",
       "      <td>20023</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/13/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>WEST ST</td>\n",
       "      <td>49300</td>\n",
       "      <td>50269.0</td>\n",
       "      <td>98.072371</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>676</td>\n",
       "      <td>20023</td>\n",
       "      <td>2002</td>\n",
       "      <td>02/13/2003 12:00:00 AM</td>\n",
       "      <td>Andover</td>\n",
       "      <td>WEST ST</td>\n",
       "      <td>49300</td>\n",
       "      <td>50269.0</td>\n",
       "      <td>98.070000</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID SerialNumber ListYear            DateRecorded     Town  \\\n",
       "0      6        20030     2002  04/24/2003 12:00:00 AM  Andover   \n",
       "1      7        20030     2002  04/24/2003 12:00:00 AM  Andover   \n",
       "2      6        20030     2002  04/24/2003 12:00:00 AM  Andover   \n",
       "3      7        20030     2002  04/24/2003 12:00:00 AM  Andover   \n",
       "4     23        20026     2002  03/04/2003 12:00:00 AM  Andover   \n",
       "5     24        20026     2002  03/04/2003 12:00:00 AM  Andover   \n",
       "6     23        20026     2002  03/04/2003 12:00:00 AM  Andover   \n",
       "7     24        20026     2002  03/04/2003 12:00:00 AM  Andover   \n",
       "8     34        20037     2002  05/05/2003 12:00:00 AM  Andover   \n",
       "9     35        20037     2002  05/05/2003 12:00:00 AM  Andover   \n",
       "10    34        20037     2002  05/05/2003 12:00:00 AM  Andover   \n",
       "11    35        20037     2002  05/05/2003 12:00:00 AM  Andover   \n",
       "12    69        20049     2002  06/18/2003 12:00:00 AM  Andover   \n",
       "13    70        20049     2002  06/18/2003 12:00:00 AM  Andover   \n",
       "14    69        20049     2002  06/18/2003 12:00:00 AM  Andover   \n",
       "15    70        20049     2002  06/18/2003 12:00:00 AM  Andover   \n",
       "16   113        20047     2002  06/16/2003 12:00:00 AM  Andover   \n",
       "17   114        20047     2002  06/16/2003 12:00:00 AM  Andover   \n",
       "18   113        20047     2002  06/16/2003 12:00:00 AM  Andover   \n",
       "19   114        20047     2002  06/16/2003 12:00:00 AM  Andover   \n",
       "20   117        20001     2002  10/21/2002 12:00:00 AM  Andover   \n",
       "21   118        20001     2002  10/21/2002 12:00:00 AM  Andover   \n",
       "22   117        20001     2002  10/21/2002 12:00:00 AM  Andover   \n",
       "23   118        20001     2002  10/21/2002 12:00:00 AM  Andover   \n",
       "24   150        20039     2002  05/19/2003 12:00:00 AM  Andover   \n",
       "25   151        20039     2002  05/19/2003 12:00:00 AM  Andover   \n",
       "26   150        20039     2002  05/19/2003 12:00:00 AM  Andover   \n",
       "27   151        20039     2002  05/19/2003 12:00:00 AM  Andover   \n",
       "28   164        20008     2002  12/02/2002 12:00:00 AM  Andover   \n",
       "29   165        20008     2002  12/02/2002 12:00:00 AM  Andover   \n",
       "..   ...          ...      ...                     ...      ...   \n",
       "242  619        20006     2002  11/07/2002 12:00:00 AM  Andover   \n",
       "243  620        20006     2002  11/07/2002 12:00:00 AM  Andover   \n",
       "244  621        20018     2002  02/10/2003 12:00:00 AM  Andover   \n",
       "245  627        20018     2002  02/10/2003 12:00:00 AM  Andover   \n",
       "246  622        20019     2002  02/10/2003 12:00:00 AM  Andover   \n",
       "247  628        20019     2002  02/10/2003 12:00:00 AM  Andover   \n",
       "248  621        20018     2002  02/10/2003 12:00:00 AM  Andover   \n",
       "249  627        20018     2002  02/10/2003 12:00:00 AM  Andover   \n",
       "250  622        20019     2002  02/10/2003 12:00:00 AM  Andover   \n",
       "251  628        20019     2002  02/10/2003 12:00:00 AM  Andover   \n",
       "252  651        20032     2002  04/25/2003 12:00:00 AM  Andover   \n",
       "253  652        20032     2002  04/25/2003 12:00:00 AM  Andover   \n",
       "254  651        20032     2002  04/25/2003 12:00:00 AM  Andover   \n",
       "255  652        20032     2002  04/25/2003 12:00:00 AM  Andover   \n",
       "256  653        20016     2002  01/21/2003 12:00:00 AM  Andover   \n",
       "257  656        20016     2002  01/21/2003 12:00:00 AM  Andover   \n",
       "258  653        20016     2002  01/21/2003 12:00:00 AM  Andover   \n",
       "259  656        20016     2002  01/21/2003 12:00:00 AM  Andover   \n",
       "260  670        20068     2002  06/03/2003 12:00:00 AM  Andover   \n",
       "261  674        20068     2002  06/03/2003 12:00:00 AM  Andover   \n",
       "262  671        20022     2002  02/13/2003 12:00:00 AM  Andover   \n",
       "263  675        20022     2002  02/13/2003 12:00:00 AM  Andover   \n",
       "264  672        20023     2002  02/13/2003 12:00:00 AM  Andover   \n",
       "265  676        20023     2002  02/13/2003 12:00:00 AM  Andover   \n",
       "266  670        20068     2002  06/03/2003 12:00:00 AM  Andover   \n",
       "267  674        20068     2002  06/03/2003 12:00:00 AM  Andover   \n",
       "268  671        20022     2002  02/13/2003 12:00:00 AM  Andover   \n",
       "269  675        20022     2002  02/13/2003 12:00:00 AM  Andover   \n",
       "270  672        20023     2002  02/13/2003 12:00:00 AM  Andover   \n",
       "271  676        20023     2002  02/13/2003 12:00:00 AM  Andover   \n",
       "\n",
       "                  Address  AssessedValue  SaleAmount  SalesRatio PropertyType  \\\n",
       "0           10 BAUSOLA RD          91800    189900.0   48.341232  Residential   \n",
       "1           10 BAUSOLA RD          91800    189900.0   48.340000  Residential   \n",
       "2           10 BAUSOLA RD          91800    189900.0   48.341232  Residential   \n",
       "3           10 BAUSOLA RD          91800    189900.0   48.340000  Residential   \n",
       "4         109 LAKESIDE DR          96700    146000.0   66.232877  Residential   \n",
       "5         109 LAKESIDE DR          96700    146000.0   66.230000  Residential   \n",
       "6         109 LAKESIDE DR          96700    146000.0   66.232877  Residential   \n",
       "7         109 LAKESIDE DR          96700    146000.0   66.230000  Residential   \n",
       "8             112 LAKE RD              0    129000.0    0.000000  Residential   \n",
       "9             112 LAKE RD          78400    129000.0   60.770000  Residential   \n",
       "10            112 LAKE RD              0    129000.0    0.000000  Residential   \n",
       "11            112 LAKE RD          78400    129000.0   60.770000  Residential   \n",
       "12     13 CHESTER BRKS LN          55200     69900.0   78.969957  Vacant Land   \n",
       "13     13 CHESTER BRKS LN          55200     69900.0   78.960000  Vacant Land   \n",
       "14     13 CHESTER BRKS LN          55200     69900.0   78.969957  Vacant Land   \n",
       "15     13 CHESTER BRKS LN          55200     69900.0   78.960000  Vacant Land   \n",
       "16           157 WALES RD          75100    116000.0   64.741379  Residential   \n",
       "17           157 WALES RD          75100    116000.0   64.740000  Residential   \n",
       "18           157 WALES RD          75100    116000.0   64.741379  Residential   \n",
       "19           157 WALES RD          75100    116000.0   64.740000  Residential   \n",
       "20   16 CHESTER BROOKS LN         203300    340912.0   59.634158  Residential   \n",
       "21   16 CHESTER BROOKS LN         203300    340912.0   59.630000  Residential   \n",
       "22   16 CHESTER BROOKS LN         203300    340912.0   59.634158  Residential   \n",
       "23   16 CHESTER BROOKS LN         203300    340912.0   59.630000  Residential   \n",
       "24          176 HEBRON RD          71000    218000.0   32.568807  Residential   \n",
       "25          176 HEBRON RD          71000    218000.0   32.560000  Residential   \n",
       "26          176 HEBRON RD          71000    218000.0   32.568807  Residential   \n",
       "27          176 HEBRON RD          71000    218000.0   32.560000  Residential   \n",
       "28       187 BOSTON HL RD         118700    219900.0   53.979081  Residential   \n",
       "29       187 BOSTON HL RD         118700    219900.0   53.970000  Residential   \n",
       "..                    ...            ...         ...         ...          ...   \n",
       "242           KINGSLEY DR         592000    900000.0   65.777778   Apartments   \n",
       "243           KINGSLEY DR         592000    900000.0   65.770000   Apartments   \n",
       "244               LAKE RD           3200      5100.0   62.745098  Vacant Land   \n",
       "245               LAKE RD           3200      5100.0   62.740000  Vacant Land   \n",
       "246               LAKE RD          44000     42500.0  103.529412  Vacant Land   \n",
       "247               LAKE RD          44000     42500.0  103.520000  Vacant Land   \n",
       "248               LAKE RD           3200      5100.0   62.745098  Vacant Land   \n",
       "249               LAKE RD           3200      5100.0   62.740000  Vacant Land   \n",
       "250               LAKE RD          44000     42500.0  103.529412  Vacant Land   \n",
       "251               LAKE RD          44000     42500.0  103.520000  Vacant Land   \n",
       "252             LT 1 RT 6          32000     34500.0   92.753623  Vacant Land   \n",
       "253             LT 1 RT 6          32000     34500.0   92.750000  Vacant Land   \n",
       "254             LT 1 RT 6          32000     34500.0   92.753623  Vacant Land   \n",
       "255             LT 1 RT 6          32000     34500.0   92.750000  Vacant Land   \n",
       "256          OLD FARMS RD          42400     63000.0   67.301587  Vacant Land   \n",
       "257          OLD FARMS RD          42400     63000.0   67.300000  Vacant Land   \n",
       "258          OLD FARMS RD          42400     63000.0   67.301587  Vacant Land   \n",
       "259          OLD FARMS RD          42400     63000.0   67.300000  Vacant Land   \n",
       "260               WEST ST              0      5000.0    0.000000  Vacant Land   \n",
       "261               WEST ST              0      5000.0    0.000000  Vacant Land   \n",
       "262               WEST ST          49300     50269.0   98.072371  Vacant Land   \n",
       "263               WEST ST          49300     50269.0   98.070000  Vacant Land   \n",
       "264               WEST ST          49300     50269.0   98.072371  Vacant Land   \n",
       "265               WEST ST          49300     50269.0   98.070000  Vacant Land   \n",
       "266               WEST ST              0      5000.0    0.000000  Vacant Land   \n",
       "267               WEST ST              0      5000.0    0.000000  Vacant Land   \n",
       "268               WEST ST          49300     50269.0   98.072371  Vacant Land   \n",
       "269               WEST ST          49300     50269.0   98.070000  Vacant Land   \n",
       "270               WEST ST          49300     50269.0   98.072371  Vacant Land   \n",
       "271               WEST ST          49300     50269.0   98.070000  Vacant Land   \n",
       "\n",
       "    ResidentialType NonUseCode Remarks  \n",
       "0     Single Family          0     NaN  \n",
       "1     Single Family          0     NaN  \n",
       "2     Single Family          0     NaN  \n",
       "3     Single Family          0     NaN  \n",
       "4     Single Family          0     NaN  \n",
       "5     Single Family          0     NaN  \n",
       "6     Single Family          0     NaN  \n",
       "7     Single Family          0     NaN  \n",
       "8     Single Family          0     NaN  \n",
       "9     Single Family          0     NaN  \n",
       "10    Single Family          0     NaN  \n",
       "11    Single Family          0     NaN  \n",
       "12              NaN          0     NaN  \n",
       "13              NaN          0     NaN  \n",
       "14              NaN          0     NaN  \n",
       "15              NaN          0     NaN  \n",
       "16    Single Family          0     NaN  \n",
       "17    Single Family          0     NaN  \n",
       "18    Single Family          0     NaN  \n",
       "19    Single Family          0     NaN  \n",
       "20    Single Family          0     NaN  \n",
       "21    Single Family          0     NaN  \n",
       "22    Single Family          0     NaN  \n",
       "23    Single Family          0     NaN  \n",
       "24    Single Family          7     NaN  \n",
       "25    Single Family          7     NaN  \n",
       "26    Single Family          7     NaN  \n",
       "27    Single Family          7     NaN  \n",
       "28    Single Family          0     NaN  \n",
       "29    Single Family          0     NaN  \n",
       "..              ...        ...     ...  \n",
       "242             NaN          0     NaN  \n",
       "243             NaN          0     NaN  \n",
       "244             NaN         12     NaN  \n",
       "245             NaN         12     NaN  \n",
       "246             NaN          0     NaN  \n",
       "247             NaN          6     NaN  \n",
       "248             NaN         12     NaN  \n",
       "249             NaN         12     NaN  \n",
       "250             NaN          0     NaN  \n",
       "251             NaN          6     NaN  \n",
       "252             NaN         14     NaN  \n",
       "253             NaN         14     NaN  \n",
       "254             NaN         14     NaN  \n",
       "255             NaN         14     NaN  \n",
       "256             NaN          0     NaN  \n",
       "257             NaN          0     NaN  \n",
       "258             NaN          0     NaN  \n",
       "259             NaN          0     NaN  \n",
       "260             NaN         17     NaN  \n",
       "261             NaN         17     NaN  \n",
       "262             NaN         17     NaN  \n",
       "263             NaN         17     NaN  \n",
       "264             NaN         17     NaN  \n",
       "265             NaN         17     NaN  \n",
       "266             NaN         17     NaN  \n",
       "267             NaN         17     NaN  \n",
       "268             NaN         17     NaN  \n",
       "269             NaN         17     NaN  \n",
       "270             NaN         17     NaN  \n",
       "271             NaN         17     NaN  \n",
       "\n",
       "[272 rows x 13 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_nonusecode(df):\n",
    "    \"\"\"\n",
    "    Some of the NonUseCodes are long strings with descriptors, which we don't need because the OPM data includes their\n",
    "    descriptions in a separate pdf. Some are also NaN.\n",
    "    This function turns all NonUseCodes into ints and sets the NaN ones to -1.\n",
    "    \"\"\"\n",
    "    new_df = df.copy()\n",
    "    new_df['NonUseCode'] = new_df['NonUseCode'].astype(str)\n",
    "    \n",
    "    for index in new_df.index:\n",
    "        # NaN case\n",
    "        current_code = new_df.loc[index, 'NonUseCode']\n",
    "        if 'na' in current_code:\n",
    "            new_df.loc[index, 'NonUseCode'] = -1\n",
    "        #0-9 case\n",
    "        elif len(current_code) < 2:\n",
    "            new_df.loc[index, 'NonUseCode'] = \"0\" + current_code\n",
    "        # XX... case, where we want to cut off additional text if there is any\n",
    "        else:\n",
    "            new_df.loc[index, 'NonUseCode'] = current_code[0:2]\n",
    "    \n",
    "    new_df['NonUseCode'] = new_df['NonUseCode'].astype(int)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_nonusecode(clean_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean SalesRatio, which flips from 50% being 0.5 to 50.0 at some point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice how, at the top, some of the sales ratios are not just AssessedValue/SaleAmount but \n",
    "# AssessedValue/SaleAmount * 100...\n",
    "clean_df.sort_values('SalesRatio', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_salesratio(df):\n",
    "    new_df = df.copy()\n",
    "    new_df['SalesRatio'] = new_df['AssessedValue'] / new_df['SaleAmount']\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_salesratio(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_raw_data(raw_data):\n",
    "    clean_data = raw_data.copy()\n",
    "    clean_data = trim_whitespace(clean_data, 'Town')\n",
    "    print(\"First clean done. (whitespace trimmed on 'Town')\")\n",
    "    clean_data = trim_whitespace(clean_data, 'Address')\n",
    "    print(\"Second clean done (whitespace trimmed on 'Address').\")\n",
    "    clean_data = convert_address_street_abbreviations(clean_data, street_conversions)\n",
    "    print(\"Third clean done (street abbreviations).\")\n",
    "    clean_data = clean_nonusecode(clean_data)\n",
    "    print(\"Fourth cleaning done (nonusecode).\")\n",
    "    clean_data = remove_duplicate_rows(clean_data)\n",
    "    print(\"Fifth cleaning done (removing duplicates).\")\n",
    "    clean_data = clean_salesratio(clean_data)\n",
    "    print(\"Sixth cleaning done (salesratio). Returning...\")\n",
    "    \n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample_raw_df()\n",
    "print(len(sample))\n",
    "new_clean_data = clean_raw_data(sample)\n",
    "new_clean_data.head()\n",
    "print(len(new_clean_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clean_csv(raw_df, year):\n",
    "    \"\"\"\n",
    "    Given a raw dataframe and a listing year, this will first extract all the listings\n",
    "    from year from raw_df. Then, it will create a clean version of that dataframe.\n",
    "    Then, it will write this to a csv file.\n",
    "    \n",
    "    The file name convention is clean_data_year_listings.csv\n",
    "    \"\"\"\n",
    "    raw_subset = raw_df[raw_df['ListYear'] == year]\n",
    "    clean_subset = clean_raw_data(raw_subset)\n",
    "    file_location = \"data/clean_data_\" + str(year) + \"_listings.csv\"\n",
    "    clean_subset.to_csv(file_location, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = make_raw_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_clean_csv(raw_df, 2001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2001 = pd.read_csv(\"data/clean_data_2001_listings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_2001 = raw_df[raw_df['ListYear'] == 2001]\n",
    "raw_2001.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2001.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_2001.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2001.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw_2001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_2001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's standardize this length test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_df(year):\n",
    "    \"\"\"Get the raw data in a dataframe for a particular ListYear year.\"\"\"\n",
    "    return raw_df[raw_df['ListYear'] == year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_df(year):\n",
    "    \"\"\"Get the clean data in a dataframe for a particular ListYear year.\n",
    "    Uses a clean csv.\"\"\"\n",
    "    filename = \"data/clean_data_\" + str(year) + \"_listings.csv\"\n",
    "    return pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(get_raw_df(2001)) == len(get_clean_df(2001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EDIT: Should not use this as a test anymore because the cleaning functions now remove duplicates, so of course the\n",
    "lengths would not be equal.\n",
    "\"\"\"\n",
    "def lengths_are_equal(year):\n",
    "    \"\"\"\n",
    "    Will get the raw and clean data for the given year and compare the lengths of these dataframes.\n",
    "    \"\"\"\n",
    "    return len(get_raw_df(year)) == len(get_clean_df(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_are_equal(2001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's produce csvs for all years and test them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_clean_csv(raw_df, 2002)\n",
    "lengths_are_equal(2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_clean_csv(raw_df, 2003)\n",
    "lengths_are_equal(2003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_clean_csv(raw_df, 2004)\n",
    "lengths_are_equal(2004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_clean_csv(raw_df, 2005)\n",
    "lengths_are_equal(2005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_clean_csv(raw_df, 2006)\n",
    "lengths_are_equal(2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_clean_csv(raw_df, 2007)\n",
    "lengths_are_equal(2007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_clean_csv(raw_df, 2008)\n",
    "lengths_are_equal(2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_clean_csv(raw_df, 2009)\n",
    "lengths_are_equal(2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_clean_csv(raw_df, 2010)\n",
    "lengths_are_equal(2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_clean_csv(raw_df, 2011)\n",
    "lengths_are_equal(2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_clean_csv(raw_df, 2012)\n",
    "lengths_are_equal(2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_clean_csv(raw_df, 2013)\n",
    "lengths_are_equal(2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_clean_csv(raw_df, 2014)\n",
    "lengths_are_equal(2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_clean_csv(raw_df, 2015)\n",
    "lengths_are_equal(2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_clean_csv(raw_df, 2016)\n",
    "lengths_are_equal(2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recombine the clean csvs into one clean dataframe and write it to a master csv file\n",
    "Note: You will NOT be able to upload this to GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.read_csv(\"data/clean_data_2001_listings.csv\")\n",
    "clean_df = clean_df.append(pd.read_csv(\"data/clean_data_2002_listings.csv\"))\n",
    "clean_df = clean_df.append(pd.read_csv(\"data/clean_data_2003_listings.csv\"))\n",
    "clean_df = clean_df.append(pd.read_csv(\"data/clean_data_2004_listings.csv\"))\n",
    "clean_df = clean_df.append(pd.read_csv(\"data/clean_data_2005_listings.csv\"))\n",
    "clean_df = clean_df.append(pd.read_csv(\"data/clean_data_2006_listings.csv\"))\n",
    "clean_df = clean_df.append(pd.read_csv(\"data/clean_data_2007_listings.csv\"))\n",
    "clean_df = clean_df.append(pd.read_csv(\"data/clean_data_2008_listings.csv\"))\n",
    "clean_df = clean_df.append(pd.read_csv(\"data/clean_data_2009_listings.csv\"))\n",
    "clean_df = clean_df.append(pd.read_csv(\"data/clean_data_2010_listings.csv\"))\n",
    "clean_df = clean_df.append(pd.read_csv(\"data/clean_data_2011_listings.csv\"))\n",
    "clean_df = clean_df.append(pd.read_csv(\"data/clean_data_2012_listings.csv\"))\n",
    "clean_df = clean_df.append(pd.read_csv(\"data/clean_data_2013_listings.csv\"))\n",
    "clean_df = clean_df.append(pd.read_csv(\"data/clean_data_2014_listings.csv\"))\n",
    "clean_df = clean_df.append(pd.read_csv(\"data/clean_data_2015_listings.csv\"))\n",
    "clean_df = clean_df.append(pd.read_csv(\"data/clean_data_2016_listings.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_length = 0\n",
    "for year in range(2001, 2017):\n",
    "    years_df = pd.read_csv(\"data/clean_data_\" + str(year) + \"_listings.csv\")\n",
    "    sum_length += len(years_df)\n",
    "\n",
    "print(\"The length of clean_df should equal the sum length of each individual year df.\")\n",
    "print(\"Length of clean_df = %d\" %len(clean_df))\n",
    "print(\"Sum length of dfs = %d\" %sum_length)\n",
    "print(\"Equal? \" + str(len(clean_df) == sum_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now write to a csv file\n",
    "clean_df.to_csv(\"data/clean_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional checks on the data\n",
    "#### Town names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['Town'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clean_df['Town'].unique()) # Should be 169 towns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional checks on the data\n",
    "#### Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['ListYear'].unique() # Should only be [2001, 2016]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional checks on the data\n",
    "#### PropertyType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['PropertyType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clean_df[clean_df['PropertyType'] == 'Condo Family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clean_df[clean_df['PropertyType'] == 'Condo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we have this one problematic row. It probably is a Condo but I could just omit it.\n",
    "clean_df[clean_df['PropertyType'] == 'C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clean_df[clean_df['PropertyType'] == 'Apartments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clean_df[clean_df['PropertyType'] == 'Apartment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df[clean_df['PropertyType'] == 'Apartment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df[clean_df['PropertyType'] == 'Apartments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apartments_sales_median = clean_df[clean_df['PropertyType'] == 'Apartments']['SaleAmount'].median()\n",
    "apartment_sales_median = clean_df[clean_df['PropertyType'] == 'Apartment']['SaleAmount'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"'Apartments': %d\\n'Apartments': %d\" %(apartments_sales_median, apartment_sales_median))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df[clean_df['PropertyType'] == '10 Mill Forest']\n",
    "# Note: I believe these are purchases of forest land for the 10 Mill Law"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional checks on the data\n",
    "#### NonUseCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['NonUseCode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2001 = pd.read_csv(\"data/clean_data_2003_listings.csv\")\n",
    "small_df = df_2001[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df['NonUseCode'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_nonusecode(raw_df[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_nonusecode(raw_df[100:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional checks on the data\n",
    "These informed the cleaning that has been done above.\n",
    "#### AssessedValue, SaleAmount, SalesRatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['AssessedValue'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['AssessedValue'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['SaleAmount'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['SaleAmount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['SalesRatio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['SalesRatio'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of these sales ratios are high. Let's make sure the assessed price and sale price are appropriately different.\n",
    "clean_df[clean_df['SalesRatio'] > 5][['Address', 'AssessedValue', 'SaleAmount', 'SalesRatio', 'PropertyType']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This makes sense. Homes with a high sales ratio should be on the lower end in terms of salesprice, which\n",
    "# would also decrease the taxed value of the home?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional checks on the data\n",
    "#### Remarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['Remarks'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['Remarks'].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like more remarks were recorded towards the end of the data (later years)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_YEAR = 2001\n",
    "MAX_YEAR = 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(MIN_YEAR, MAX_YEAR):\n",
    "    \"\"\"\n",
    "    Pass in a range of years. Will combine all of the CSVs corresponding to that time range into one main datafame.\n",
    "    This dataframe will be cleaned in various ways:\n",
    "        1. Remove leading and trailing whitespace\n",
    "        2. Replace double-spaces with single-spaces in the Address field\n",
    "        3. Replace abbreviations like \"LN\" and \"RD\" in the Address field with their full names (\"LANE\", \"ROAD\", etc.)\n",
    "        4. Fix NonUseCodes so that they are only two-digit or less integers.\n",
    "        5. Remove duplicate rows.\n",
    "    \"\"\"\n",
    "    # Combine the year-by-year clean csvs, which are located at 'data/clean_data_20xx_listings.csv'\n",
    "    df = pd.read_csv('data/clean_data_' + str(MIN_YEAR) + '_listings.csv')\n",
    "    for year in range(MIN_YEAR+1, MAX_YEAR+1):\n",
    "        df = df.append(pd.read_csv('data/clean_data_' + str(year) + '_listings.csv'))\n",
    "\n",
    "    # Now remove the index column\n",
    "    #df = df.drop('Unnamed: 0', 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_dataframe(MIN_YEAR, MAX_YEAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional checks on the data\n",
    "#### Looking for duplicate transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are all the SerialNumbers unique?\n",
    "len(df['SerialNumber'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['SerialNumber'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many duplicates are there?\n",
    "len(df['SerialNumber']) - len(df['SerialNumber'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_serial_number(df):\n",
    "    \"\"\"\n",
    "    Returns a serial number from df at random.\n",
    "    \"\"\"\n",
    "    random_index = random.randint(0, len(df))\n",
    "    random_index\n",
    "    random_serial = df.iloc[random_index]['SerialNumber']\n",
    "    return random_serial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_all_rows_with_random_serial_number(df):\n",
    "    \"\"\"\n",
    "    Returns a subset of df based on a random serial number.\n",
    "    \"\"\"\n",
    "    random_serial = get_random_serial_number(df)\n",
    "    subset = df[df['SerialNumber'] == random_serial]\n",
    "    #print(\"SERIAL #: %d\\t\\tSIZE: %d\" %(random_serial, len(subset)))\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_all_rows_with_random_serial_number(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings\n",
    "* First 1-2 digits of serial number represent the last 1-2 digits of the year (i.e. 2015 serial numbers start with '15'. 2004 serial numbers start with '4')\n",
    "* Does not seem to repeat towns in a year. So if there are 10 rows with the same serial number in 2010, those will all be from 10 differernt towns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_duplicate_row_removal(df):\n",
    "    \"\"\"\n",
    "    Raises an exception if there is a duplicate row, judged by whether the length of unique towns is\n",
    "    not equal to the length of a sample subset of rows with the same serial number.\n",
    "    \"\"\"\n",
    "    fails_test_table = None\n",
    "    for i in range(0,50):\n",
    "        # Are there rows with the same serial number AND same Town?\n",
    "        sample_subset = show_all_rows_with_random_serial_number(df)\n",
    "        passes_test = len(sample_subset) == len(sample_subset['Town'].unique())     # Best case scenario: lengths are equal.\n",
    "\n",
    "        if not passes_test:\n",
    "            fails_test_table = sample_subset\n",
    "            raise Exception(\"Test failed! Duplicate row likely.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fails_test_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings\n",
    "* If the same serial number occurrs among rows with the same year and town, they are duplicates.\n",
    "* One row seems to be the partially rounded version of the other, and the rounded one is usually the second one.\n",
    "* The rounding here is pretty inconsequential, I think, as these are not measurements that demand decimal accuracy.\n",
    "\n",
    "__Fix this with a clean that removes duplicates, preferring the first row over the second or subsequent duplicate rows.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_dataframe(MIN_YEAR, MAX_YEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_duplicates = remove_duplicate_rows(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 50):\n",
    "    randomly = show_all_rows_with_random_serial_number(df_no_duplicates)\n",
    "    passes_test = len(randomly['Address'].unique()) == len(randomly)\n",
    "    print(passes_test)\n",
    "    if passes_test == False:\n",
    "        break\n",
    "randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
